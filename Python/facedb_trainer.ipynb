{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqJ0HcmGQt5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "#download face database.\n",
        "if not os.path.isfile('./FaceDB.zip'):\n",
        "  !gdown --id 'replace this with google drive link'\n",
        "#or download it from wherever you want it\n",
        "\n",
        "#unzip the database.\n",
        "if not os.path.isdir('./FaceDB'):\n",
        "  !unzip -oq FaceDB.zip -d \"./FaceDB\"\n",
        "\n",
        "#create folder for trained models to be saved.\n",
        "if not os.path.isdir('./saved_models'):\n",
        "  os.mkdir('./saved_models')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f3cabVKVrDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "#using tensorflow's keras implementation\n",
        "#so the models can be converted to .tflite.\n",
        "keras = tf.keras\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCjTECIQR-f7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "#getting images from a path.\n",
        "#path must have sub-folders.\n",
        "#each sub-folders contains pictures of one person.\n",
        "def ImgClassLists(path, imageExtension):\n",
        "    imagePaths = []\n",
        "    classes = []\n",
        "    \n",
        "    #walk the path.\n",
        "    for root, _, files in sorted(os.walk(path)):\n",
        "        #sort the files iterator.\n",
        "        for file in sorted(files):\n",
        "            if file.endswith(imageExtension):\n",
        "                #get image paths.\n",
        "                imagePath = os.path.join(root, file)\n",
        "                imagePaths.append(imagePath)\n",
        "                #for each sub-folder provide an unique class name.\n",
        "                className = root[len(path) : ]\n",
        "                classes.append(className)\n",
        "    #turn class names into numbers.\n",
        "    #from [\"class-a\", \"class-a\", \"class-b\", \"class-b\", \"class-b\", \"class-c\"]\n",
        "    #to   [0        , 0        ,  1       ,  1       ,  1       ,  2       ].\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    le.fit(classes)\n",
        "    classes = le.transform(classes)\n",
        "    return (imagePaths, classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZjQppOXXBR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#MobileNet implementation taken from the TF Keras library.\n",
        "\n",
        "def MobileNet(shape, num_classes, alpha = 1, include_top = True, weights = None, num_inputs = None):\n",
        "    model = tf.keras.applications.MobileNet(input_shape = shape, alpha = alpha, include_top = include_top, weights = weights, classes = num_classes)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsvNUqVBZFqs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Keras EffNet implementation taken from\n",
        "#https://github.com/arthurdouillard/keras-effnet.\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import *\n",
        "from keras.activations import *\n",
        "from keras.callbacks import *\n",
        "\n",
        "def get_post(x_in):\n",
        "    x = LeakyReLU()(x_in)\n",
        "    x = BatchNormalization()(x)\n",
        "    return x\n",
        "\n",
        "def get_block(x_in, ch_in, ch_out):\n",
        "    x = Conv2D(ch_in,\n",
        "               kernel_size=(1, 1),\n",
        "               padding='same',\n",
        "               use_bias=False)(x_in)\n",
        "    x = get_post(x)\n",
        "\n",
        "    x = DepthwiseConv2D(kernel_size=(1, 3), padding='same', use_bias=False)(x)\n",
        "    x = get_post(x)\n",
        "    x = MaxPool2D(pool_size=(2, 1),\n",
        "                  strides=(2, 1))(x) # Separable pooling\n",
        "\n",
        "    x = DepthwiseConv2D(kernel_size=(3, 1),\n",
        "                        padding='same',\n",
        "                        use_bias=False)(x)\n",
        "    x = get_post(x)\n",
        "\n",
        "    x = Conv2D(ch_out,\n",
        "               kernel_size=(2, 1),\n",
        "               strides=(1, 2),\n",
        "               padding='same',\n",
        "               use_bias=False)(x)\n",
        "    x = get_post(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def Effnet(input_shape, nb_classes, include_top=True, weights=None, num_inputs=None):\n",
        "    x_in = Input(shape=input_shape)\n",
        "\n",
        "    x = get_block(x_in, 32, 64)\n",
        "    x = get_block(x, 64, 128)\n",
        "    x = get_block(x, 128, 256)\n",
        "\n",
        "    if include_top:\n",
        "        x = Flatten()(x)\n",
        "        x = Dense(nb_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=x_in, outputs=x)\n",
        "\n",
        "    if weights is not None:\n",
        "        model.load_weights(weights, by_name=True)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed-qNEqxmU_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ShuffleNet implementation taken from\n",
        "#https://github.com/arthurdouillard/keras-shufflenet.\n",
        "#Validation to .tflite model doesn't work, so the model is scrapped\n",
        "#for .tflite conversion and integration.\n",
        "'''\n",
        "from keras.models import Model\n",
        "from keras.layers import *\n",
        "from keras.activations import *\n",
        "from keras.callbacks import *\n",
        "import keras.backend as K\n",
        "\n",
        "\n",
        "def _stage(tensor, nb_groups, in_channels, out_channels, repeat):\n",
        "    x = _shufflenet_unit(tensor, nb_groups, in_channels, out_channels, 2)\n",
        "\n",
        "    for _ in range(repeat):\n",
        "        x = _shufflenet_unit(x, nb_groups, out_channels, out_channels, 1)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def _pw_group(tensor, nb_groups, in_channels, out_channels):\n",
        "    \"\"\"Pointwise grouped convolution.\"\"\"\n",
        "    nb_chan_per_grp = in_channels // nb_groups\n",
        "\n",
        "    pw_convs = []\n",
        "    for grp in range(nb_groups):\n",
        "        x = Lambda(lambda x: x[:, :, :, nb_chan_per_grp * grp: nb_chan_per_grp * (grp + 1)])(tensor)\n",
        "        grp_out_chan = int(out_channels / nb_groups + 0.5)\n",
        "\n",
        "        pw_convs.append(\n",
        "            Conv2D(grp_out_chan,\n",
        "                   kernel_size=(1, 1),\n",
        "                   padding='same',\n",
        "                   use_bias=False,\n",
        "                   strides=1)(x)\n",
        "        )\n",
        "\n",
        "    return Concatenate(axis=-1)(pw_convs)\n",
        "\n",
        "\n",
        "def _shuffle(x, nb_groups):\n",
        "    def shuffle_layer(x):\n",
        "        _, w, h, n = K.int_shape(x)\n",
        "        nb_chan_per_grp = n // nb_groups\n",
        "\n",
        "        x = K.reshape(x, (-1, w, h, nb_chan_per_grp, nb_groups))\n",
        "        x = K.permute_dimensions(x, (0, 1, 2, 4, 3)) # Transpose only grps and chs\n",
        "        x = K.reshape(x, (-1, w, h, n))\n",
        "\n",
        "        return x\n",
        "\n",
        "    return Lambda(shuffle_layer)(x)\n",
        "\n",
        "\n",
        "def _shufflenet_unit(tensor, nb_groups, in_channels, out_channels, strides, shuffle=True, bottleneck=4):\n",
        "    bottleneck_channels = out_channels // bottleneck\n",
        "\n",
        "    x = _pw_group(tensor, nb_groups, in_channels, bottleneck_channels)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    if shuffle:\n",
        "        x = _shuffle(x, nb_groups)\n",
        "\n",
        "    x = DepthwiseConv2D(kernel_size=(3, 3),\n",
        "                        padding='same',\n",
        "                        use_bias=False,\n",
        "                        strides=strides)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "\n",
        "    x = _pw_group(x, nb_groups, bottleneck_channels,\n",
        "                  out_channels if strides < 2 else out_channels - in_channels)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    if strides < 2:\n",
        "        x = Add()([tensor, x])\n",
        "    else:\n",
        "        avg = AveragePooling2D(pool_size=(3, 3),\n",
        "                               strides=2,\n",
        "                               padding='same')(tensor)\n",
        "\n",
        "        x = Concatenate(axis=-1)([avg, x])\n",
        "\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def _info(nb_groups):\n",
        "    return {\n",
        "        1: [24, 144, 288, 576],\n",
        "        2: [24, 200, 400, 800],\n",
        "        3: [24, 240, 480, 960],\n",
        "        4: [24, 272, 544, 1088],\n",
        "        8: [24, 384, 768, 1536]\n",
        "    }[nb_groups], [None, 3, 7, 3]\n",
        "\n",
        "\n",
        "def ShuffleNet(input_shape, nb_classes, include_top=True, weights=None, nb_groups=8, num_inputs=None):\n",
        "    x_in = Input(shape=input_shape)\n",
        "\n",
        "    x = Conv2D(24,\n",
        "               kernel_size=(3, 3),\n",
        "               strides=2,\n",
        "               use_bias=False,\n",
        "               padding='same')(x_in)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = MaxPooling2D(pool_size=(3, 3),\n",
        "                     strides=2,\n",
        "                     padding='same')(x)\n",
        "\n",
        "    channels_list, repeat_list = _info(nb_groups)\n",
        "    for i, (out_channels, repeat) in enumerate(zip(channels_list[1:], repeat_list[1:]), start=1):\n",
        "        x = _stage(x, nb_groups, channels_list[i-1], out_channels, repeat)\n",
        "\n",
        "    if include_top:\n",
        "        x = GlobalAveragePooling2D()(x)\n",
        "        x = Dense(nb_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=x_in, outputs=x)\n",
        "\n",
        "    if weights is not None:\n",
        "        model.load_weights(weights, by_name=True)\n",
        "\n",
        "    return model\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxB3j9KKHARH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#L-CNN implementation taken from\n",
        "#https://github.com/radu-dogaru/LightWeight_Binary_CNN_and_ELM_Keras.\n",
        "\n",
        "#Radu Dogaru and Ioana Dogaru, \"BCONV-ELM: Binary Weights Convolutional Neural\n",
        "#Network Simulator based on Keras/Tensorflow, for Low Complexity\n",
        "#Implementations\", Proceedings of the ISEEE 2019 conference, submitted.\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation\n",
        "from keras.layers import Conv2D, DepthwiseConv2D, MaxPooling2D, AveragePooling2D \n",
        "\n",
        "def LCNN(input_shape, num_classes, include_top=True, weights=None, num_inputs=None):\n",
        "    nhid1 = 0 # hidden-1 neurons (put 0 if nhid2=0, or a desired value)\n",
        "    nhid2 = 0 # hidden-2 neurons (take 0 for 0 or 1 hidden layer)\n",
        "    nr_conv = 2 # 0, 1, 2 sau 3  (number of convolution layers - generally, a bigger number allows for better accuracy with the same complexity)\n",
        "    filtre1=8 ; filtre2=8 ; filtre3=8  # filters (kernels) per each layer\n",
        "    csize1=3; csize2=3 ; csize3=3      # convolution kernel size (square kernel) \n",
        "    psize1=4; psize2=4 ; psize3=4      # pooling size (square)\n",
        "    str1=2; str2=2; str3=2             # stride pooling (downsampling rate)\n",
        "    pad='same'; # padding style ('valid' is also an alternative)\n",
        "    type_conv=2 # 1='depth_wise' or 2='normal' \n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    if nr_conv>=1:\n",
        "        if type_conv==2:\n",
        "            model.add(Conv2D(filtre1, padding=pad, kernel_size=(csize1, csize1), input_shape=input_shape))\n",
        "        elif type_conv==1:\n",
        "            model.add(DepthwiseConv2D(kernel_size=csize2, padding=pad, input_shape=input_shape, depth_multiplier=filtre1, use_bias=False))\n",
        "        #model.add(Activation('relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(psize1, psize1),strides=(str1,str1),padding=pad))\n",
        "        #model.add(Activation('relu'))\n",
        "        if nr_conv>=2:\n",
        "            if type_conv==2:\n",
        "                model.add(Conv2D(filtre2, padding=pad, kernel_size=(csize2, csize2)) )\n",
        "            elif type_conv==1:\n",
        "                model.add(DepthwiseConv2D(kernel_size=csize2, padding=pad, depth_multiplier=filtre2, use_bias=False))\n",
        "            model.add(Activation('relu'))\n",
        "            model.add(MaxPooling2D(pool_size=(psize2, psize2),strides=(str2,str2),padding=pad))\n",
        "            #model.add(Activation('relu'))\n",
        "            if nr_conv==3:\n",
        "                if type_conv==2:\n",
        "                    model.add(Conv2D(filtre3, padding=pad, kernel_size=(csize3, csize3)) )\n",
        "                elif type_conv==1:\n",
        "                    model.add(DepthwiseConv2D(kernel_size=csize3, padding=pad, depth_multiplier=filtre3, use_bias=False))\n",
        "                #model.add(Activation('relu'))\n",
        "                model.add(MaxPooling2D(pool_size=(psize3, psize3),strides=(str3,str3),padding=pad))\n",
        "                #model.add(Activation('relu'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(Flatten())\n",
        "        #model.add(Activation('relu'))\n",
        "        #model.add(Dropout(0.25))\n",
        "    elif nr_conv==0:\n",
        "        model.add(Flatten(input_shape=input_shape))\n",
        "    # ---- first fc hidden layer  \n",
        "    if nhid1>0:\n",
        "        model.add(Dense(nhid1, activation='relu'))\n",
        "        #model.add(Dropout(0.5))\n",
        "    # ---- second fc hidden layer \n",
        "    if nhid2>0:\n",
        "        model.add(Dense(nhid2, activation='relu'))\n",
        "    #   model.add(Dropout(0.2))\n",
        "    #   output layer \n",
        "    if (nhid1+nhid2)==0:\n",
        "        model.add(Dense(num_classes, activation='softmax',input_shape=(num_inputs,)))\n",
        "    else: \n",
        "        model.add(Dense(num_classes, activation='softmax'))\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMwIU9k5XUWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#get a valid image size from the supported sizes array.\n",
        "#if optional argument is provided, the function returns the closest image size\n",
        "#from the supported sizes array to the wanted image size.\n",
        "def calc_supported_image_size(image, supported_sizes, wanted_image_size = None):\n",
        "    \n",
        "    if wanted_image_size is None:\n",
        "        image_shape = image.shape\n",
        "        wanted_image_size = int((image_shape[0] + image_shape[1]) / 2)\n",
        "    \n",
        "    #calculate the closest differences from the wanted image sizes to the\n",
        "    #supported sizes.\n",
        "    min_diff_size = abs(wanted_image_size - supported_sizes[0])\n",
        "    min_diff_size_idx = 0\n",
        "    for idx in range(1, len(supported_sizes)):\n",
        "        temp_min_diff_size = abs(wanted_image_size - supported_sizes[idx])\n",
        "        if temp_min_diff_size < min_diff_size:\n",
        "            min_diff_size = temp_min_diff_size\n",
        "            min_diff_size_idx = idx\n",
        "    \n",
        "    #return the closest size to the wanted image size from the supported\n",
        "    #size array.\n",
        "    return supported_sizes[min_diff_size_idx]\n",
        "\n",
        "#split the images into test and train image sets.\n",
        "def image_split(splittableImagePaths, splittableClasses, test_size = 0.25, wanted_image_size = None, supported_sizes = [128]):\n",
        "  #get valid image size\n",
        "  image_size = calc_supported_image_size(np.asarray(Image.open(splittableImagePaths[0])), supported_sizes = supported_sizes, wanted_image_size = wanted_image_size)\n",
        "\n",
        "  #populate array with images that have been resized to the calculated image size.\n",
        "  splittableImages = []\n",
        "\n",
        "  #convert images to rgb for working with color images.\n",
        "  #resize images to the valid image size.\n",
        "  #pixel values range from 0 to 255.\n",
        "  for img in splittableImagePaths:\n",
        "      splittableImages.append(np.asarray(Image.open(img).convert('RGB').resize((image_size, image_size)), dtype = np.uint8))\n",
        "\n",
        "  #stratify is used for choosing an equal amount of pictures from each class\n",
        "  #for the test and train image sets respectively.\n",
        "  #test size is used to choose the percentage of how many images\n",
        "  #will be used for testing.\n",
        "  x_train, x_test, y_train, y_test =  train_test_split(splittableImages, splittableClasses, test_size = test_size, stratify = splittableClasses)\n",
        "  #converts the classes array to a binary matrix\n",
        "  #that is understandable to the model algorithm.\n",
        "  #example:\n",
        "  #y_train          =   [0, 2, 1]\n",
        "  #encoded_y_train  =  [[1, 0, 0],\n",
        "  #                     [0, 0, 1],\n",
        "  #                     [0, 1, 0]] \n",
        "  encoded_y_train = to_categorical(y_train)\n",
        "  encoded_y_test = to_categorical(y_test)\n",
        "  return np.array(x_train), np.array(x_test), np.array(encoded_y_train), np.array(encoded_y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSZ8Y8BpbJSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import time as ti\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "#supported databases dictionary with their image extensions.\n",
        "databases = {\"ESSEX\" : \".jpg\", \"JAFFE\" : \".tiff\", \"ORL\" : \".pgm\"}\n",
        "\n",
        "#supported models dictionary with their function implementations.\n",
        "models = {\"MobileNet\" : MobileNet, \"EffNet\" : Effnet, \"LCNN\" : LCNN}\n",
        "\n",
        "#model accuracy to be hit.\n",
        "#any accuracies bigger than that will be ignored.\n",
        "threshold_acc = 0.985\n",
        "\n",
        "#go through all models.\n",
        "for current_model in models:\n",
        "    #go through all databases.\n",
        "    for current_database in databases:\n",
        "\n",
        "        print(\"----------------{} + {}----------------\".format(current_database, current_model))\n",
        "\n",
        "        test_size = 0.25\n",
        "\n",
        "        #get image paths and classes.\n",
        "        (splittableImagePaths, splittableClasses) = ImgClassLists(\"./FaceDB/{}/\".format(current_database), databases[current_database])\n",
        "\n",
        "        #split the images into different datasets.\n",
        "        #x_train = images to use for the training process.\n",
        "        #y_train = classes to use for the training process.\n",
        "        #x_test = images to use for the testing process.\n",
        "        #y_test = classes to use for the testing process.\n",
        "        x_train, x_test, y_train, y_test = image_split(splittableImagePaths, splittableClasses, test_size = test_size)\n",
        "        input_shape = np.shape(x_train)[1:4]\n",
        "        num_classes = np.shape(y_train)[1]\n",
        "\n",
        "        print(\"Using database:    {}\".format(current_database))\n",
        "        print(\"Image shape:       {}\".format(input_shape))\n",
        "        print(\"Number of images:  {}\".format(len(splittableImagePaths)))\n",
        "        print(\"Number of classes: {}\".format(num_classes))\n",
        "\n",
        "        #directory to save the model into.\n",
        "        saved_model_path = './saved_models/'\n",
        "        #model to be saved under this name.\n",
        "        saved_model_name = 'model_{}_{}'.format(current_database, current_model)\n",
        "        #model extension.\n",
        "        saved_model_ext = '.h5'\n",
        "        #converted lite model extension.\n",
        "        saved_model_lite = '.tflite'\n",
        "\n",
        "        #learning rate value.\n",
        "        lr = 0.001\n",
        "\n",
        "        #loss function.\n",
        "        loss = 'categorical_crossentropy'\n",
        "        \n",
        "        #optimizer to be used.\n",
        "        optimizer = tf.keras.optimizers.Adam(lr = lr)\n",
        "        \n",
        "        #metrics to be tracked.\n",
        "        metrics = ['accuracy']\n",
        "\n",
        "        #call the function to invoke chosen model.\n",
        "        model = models[current_model](input_shape, num_classes, num_inputs = np.shape(x_test)[1])\n",
        "\n",
        "        #compile model with set parameters\n",
        "        model.compile(loss = loss, optimizer = optimizer, metrics = metrics)\n",
        "        print(\"Using deep learning model: {}\".format(current_model))\n",
        "        print(\"Loss function:             {}\".format(loss))\n",
        "        print(\"Metrics array:             {}\".format(metrics))\n",
        "        print(\"Optimizer config:          {}\".format(optimizer))\n",
        "        print(\"Learning rate:             {}\".format(lr))\n",
        "\n",
        "        #train \"batch_size\" images at a time.\n",
        "        batch_size = 5\n",
        "\n",
        "        #how many times to repeat the training process .\n",
        "        epochs = 100\n",
        "\n",
        "        #scores array to count the accuracy value for each epoch.\n",
        "        scores = np.zeros(epochs)\n",
        "        best_acc = 0\n",
        "        best_epoch = 0\n",
        "        last_epoch = 0\n",
        "\n",
        "        print('--- {} training images, {} test images, {} batch size ---'.format(len(x_train), len(x_test), batch_size))\n",
        "\n",
        "        #timestamp before beginning training.\n",
        "        t1 = ti.time()\n",
        "        for k in range(epochs):\n",
        "            print('\\nEpoch {} out of {} running...'.format(k + 1, epochs))\n",
        "            #train the model with the provided train data set.\n",
        "            model.fit(x_train, y_train, batch_size = batch_size, verbose = 1, epochs = 1, validation_data = (x_test, y_test))\n",
        "            \n",
        "            #check the accuracy of the model with the test data set.\n",
        "            score = model.evaluate(x_test, y_test, verbose = 0)\n",
        "\n",
        "            #remember best accuracy.\n",
        "            scores[k] = score[1]\n",
        "            last_epoch = k + 1\n",
        "            if score[1] > best_acc:\n",
        "                best_acc = score[1]\n",
        "                best_epoch = last_epoch\n",
        "                print('Improved accuracy on epoch {} : {}%'.format(k + 1, best_acc * 100))\n",
        "                #remember best weight values from best accuracy.\n",
        "                best_weights = model.get_weights()\n",
        "                if best_acc > threshold_acc:\n",
        "                    print('Threshold accuracy surpassed. Stopping training at epoch {} out of {}.'.format(k + 1, epochs))\n",
        "                    break\n",
        "        #timestamp after finishing training.\n",
        "        t2 = ti.time()\n",
        "\n",
        "        print('\\nBest accuracy on epoch {} out of {} : {}%'.format(best_epoch, epochs, best_acc * 100))\n",
        "        print('Fitting took {} seconds.'.format(t2 - t1))\n",
        "\n",
        "        #set the best weights for the model.\n",
        "        model.set_weights(best_weights)\n",
        "\n",
        "        #save the trained model as a .h5 file.\n",
        "        model.save(saved_model_path + saved_model_name + saved_model_ext)\n",
        "\n",
        "        #plot the scores array for each database and model.\n",
        "        plt.figure()\n",
        "        plt.title(\"{} + {}\".format(current_database, current_model))\n",
        "        plt.xlim(0, last_epoch)\n",
        "        plt.ylim(0, 1)\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Accuracy (0 - min, 1 - max)')\n",
        "        plt.plot(scores[:last_epoch])\n",
        "\n",
        "        print('\\nEvaluating {}\\n'.format(saved_model_name + saved_model_ext))\n",
        "        t1 = ti.time()\n",
        "        #evaluate the trained model.\n",
        "        score = model.evaluate(x_test, y_test, verbose = 1)\n",
        "        t2 = ti.time()\n",
        "        print('\\nTest accuracy: {}%'.format(score[1] * 100))\n",
        "        print('Test duration : {} seconds'.format(t2 - t1))\n",
        "        print('Latency (per input sample) : {} ms.'.format(1000*(t2-t1)/np.shape(x_test)[0]))\n",
        "\n",
        "        print('Converting model to .tflite...')\n",
        "        #loading the model from a filepath.\n",
        "        model = load_model(saved_model_path + saved_model_name + saved_model_ext)\n",
        "        \n",
        "        #initializing tflite converter.\n",
        "        tflite_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "        \n",
        "        #the tflite model can use the post training quantize\n",
        "        #further into development.\n",
        "        tflite_converter.post_training_quantize=True\n",
        "        \n",
        "        #convert the .h5 keras file to a .tflite file.\n",
        "        tflite_model = tflite_converter.convert()\n",
        "\n",
        "        #save the model.\n",
        "        open(saved_model_path + saved_model_name + saved_model_lite, \"wb\").write(tflite_model)\n",
        "\n",
        "        print('Validating .tflite model...')\n",
        "        #checking if the conversion was done successfully.\n",
        "        interpreter = tf.lite.Interpreter(model_path = saved_model_path + saved_model_name + saved_model_lite)\n",
        "        interpreter.allocate_tensors()\n",
        "\n",
        "        input_details = interpreter.get_input_details()\n",
        "        output_details = interpreter.get_output_details()\n",
        "\n",
        "        input_shape = input_details[0]['shape']\n",
        "        input_data = np.array(np.random.random_sample(input_shape), dtype = np.float32)\n",
        "\n",
        "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "        interpreter.invoke()\n",
        "\n",
        "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "        print(output_data)\n",
        "    model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkHMs-Ib2cB8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#zip the saved models folder.\n",
        "!zip -r saved_models.zip ./saved_models/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJ0F2plA1dXs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#download the zip.\n",
        "from google.colab import files\n",
        "files.download(\"saved_models.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EenTJO3RF4cz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#generating labels file.\n",
        "#labels file is used in the .tflite integration process.\n",
        "#labels file is used to get the classes from the image databases\n",
        "#and for each of them to be given a confidence score.\n",
        "databases = {\"ESSEX\" : \".jpg\", \"JAFFE\" : \".tiff\", \"ORL\" : \".pgm\"}\n",
        "for db in databases:\n",
        "    #get the classes from the image folder.\n",
        "    classes = []\n",
        "    path = \"./FaceDB/{}/\".format(db)\n",
        "    for root, _, files in sorted(os.walk(path)):\n",
        "        #sort the files iterator.\n",
        "        for file in sorted(files):\n",
        "            if file.endswith(databases[db]):\n",
        "                #class name is based on the folder it's contained in.\n",
        "                className = root[len(path) : ]\n",
        "                classes.append(className)\n",
        "    #get only unique entries from the classes array.\n",
        "    unique = []\n",
        "    for cls in classes:\n",
        "        if cls not in unique:\n",
        "            unique.append(cls)\n",
        "    #save the unique class entries in a text file.\n",
        "    with open('labels_{}.txt'.format(db), 'w') as f:\n",
        "        f.write('\\n'.join(unique))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "facedb_trainer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}